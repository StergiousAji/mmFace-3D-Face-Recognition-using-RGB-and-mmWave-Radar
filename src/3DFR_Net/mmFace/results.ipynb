{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"results.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Accuracies: \n",
      "[90.4498  85.5469  88.87025 82.83585 79.8393  90.71385 91.05445 67.18115\n",
      " 82.0225 ]\n",
      "\n",
      "Averaged Micro-Accuracies: \n",
      "[0.9033  0.85545 0.86035 0.79495 0.7438  0.89355 0.8714  0.53845 0.76045]\n",
      "\n",
      "Averaged F_{0.5} Scores: \n",
      "[0.90345 0.8616  0.886   0.8251  0.79195 0.90585 0.9021  0.63625 0.8107 ]\n",
      "\n",
      "Macro-Averaged AUCs: \n",
      "[0.9514, 0.9346, 0.9341, 0.8803, 0.8543, 0.916, 0.919, 0.7715, 0.8769]\n",
      "\n",
      "KL Divergences: \n",
      "[0.4505, 0.8362, 0.2961, 0.2079, 0.2469, 0.2439, 0.2627, 1.425, 0.147]\n",
      "\n",
      "Coverages: \n",
      "[99.8698, 100.0, 96.8099, 95.9635, 93.1641, 98.5026, 95.7031, 80.1432, 92.7083]\n",
      "\n",
      "Subject Accuracy: \n",
      "[81.4863, 71.4193, 84.7344, 87.0421, 81.9008, 85.2611, 84.6939, 40.5361, 88.5534]\n",
      "\n",
      "Liveness Accuracy: \n",
      "[99.4133, 99.6745, 93.0061, 78.6296, 77.7778, 96.1666, 97.415, 93.8262, 75.4916]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracies = np.array([x[\"SUBJECT\"][\"Accuracy\"] + x[\"LIVENESS\"][\"Accuracy\"] for x in data.values()])\n",
    "f1_scores = np.array([x[\"SUBJECT\"][\"Weighted-Averaged F-Score\"] + x[\"LIVENESS\"][\"Weighted-Averaged F-Score\"] for x in data.values()])\n",
    "micro_accuracies = np.array([x[\"SUBJECT\"][\"Micro-Accuracy\"] + x[\"LIVENESS\"][\"Micro-Accuracy\"] for x in data.values()])\n",
    "\n",
    "print(f\"Averaged Accuracies: \\n{accuracies / 2}\\n\")\n",
    "print(f\"Averaged Micro-Accuracies: \\n{micro_accuracies / 2}\\n\")\n",
    "print(f\"Averaged F_{{0.5}} Scores: \\n{f1_scores / 2}\\n\")\n",
    "print(f\"Macro-Averaged AUCs: \\n{[x['Macro-Averaged AUC'] for x in data.values()]}\\n\")\n",
    "print(f\"KL Divergences: \\n{[x['KL Divergence'] for x in data.values()]}\\n\")\n",
    "print(f\"Coverages: \\n{[x['Coverage'] for x in data.values()]}\\n\")\n",
    "print(f\"Subject Accuracy: \\n{[x['SUBJECT']['Accuracy'] for x in data.values()]}\\n\")\n",
    "print(f\"Liveness Accuracy: \\n{[x['LIVENESS']['Accuracy'] for x in data.values()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.41645\n",
      "[91.65105 81.08615 91.88125 84.81835 77.77095 90.7027  91.34445 67.42825\n",
      " 77.40465]\n",
      "[14.2464   3.6815  14.4766   7.4137   0.3663  13.29805 13.9398 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.63176428571428"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accs = accuracies / 2\n",
    "diffs = mean_accs - mean_accs[-1]#(np.mean(mean_accs[-2:]))\n",
    "print((np.mean(mean_accs[-2:])))\n",
    "print(mean_accs)\n",
    "print(diffs[:-2])\n",
    "np.mean(diffs[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(\"results_rlc.json\", 'r') as f:\n",
    "    data_rlc = json.load(f)\n",
    "\n",
    "with open(\"results_dlc.json\", 'r') as f:\n",
    "    data_dlc = json.load(f)\n",
    "\n",
    "with open(\"results_o.json\", 'r') as f:\n",
    "    data_o = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference (DLC): 0.42548571428571336\n",
      "Mean difference (O): 3.861157142857143\n"
     ]
    }
   ],
   "source": [
    "subject_accs_rlc = np.array([x['SUBJECT']['Accuracy'] for x in data_rlc.values()])\n",
    "subject_accs_dlc = np.array([x['SUBJECT']['Accuracy'] for x in data_dlc.values()])\n",
    "subject_accs_o = np.array([x['SUBJECT']['Accuracy'] for x in data_o.values()])\n",
    "\n",
    "print(f\"Mean difference (DLC): {np.mean(subject_accs_rlc[:-2] - subject_accs_dlc[:-2])}\")\n",
    "print(f\"Mean difference (O): {np.mean(subject_accs_rlc[:-2] - subject_accs_o[:-2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference (DLC): -0.20595714285714248\n",
      "Mean difference (O): 1.7003000000000026\n"
     ]
    }
   ],
   "source": [
    "liveness_accs_rlc = np.array([x['LIVENESS']['Accuracy'] for x in data_rlc.values()])\n",
    "liveness_accs_dlc = np.array([x['LIVENESS']['Accuracy'] for x in data_dlc.values()])\n",
    "liveness_accs_o = np.array([x['LIVENESS']['Accuracy'] for x in data_o.values()])\n",
    "\n",
    "print(f\"Mean difference (DLC): {np.mean(liveness_accs_rlc[:-2] - liveness_accs_dlc[:-2])}\")\n",
    "print(f\"Mean difference (O): {np.mean(liveness_accs_rlc[:-2] - liveness_accs_o[:-2])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
