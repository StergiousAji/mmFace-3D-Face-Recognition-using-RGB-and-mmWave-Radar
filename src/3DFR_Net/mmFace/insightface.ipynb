{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InsightFace for RGB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'enable_skip_layer_norm_strict_mode': '0'}, 'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'enable_skip_layer_norm_strict_mode': '0'}, 'CPUExecutionProvider': {}}\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "from insightface.app.common import Face\n",
    "from insightface.model_zoo import model_zoo\n",
    "import os\n",
    "# REQUIRED FOR CUDA TO BE USED\n",
    "import torch\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "det_model_path = os.path.join(BASE_DIR, \"../models\", \"buffalo_l\", \"det_10g.onnx\")\n",
    "rec_model_path = os.path.join(BASE_DIR, \"../models\", \"buffalo_l\", \"w600k_r50.onnx\")\n",
    "\n",
    "det_model = model_zoo.get_model(det_model_path)\n",
    "rec_model = model_zoo.get_model(rec_model_path)\n",
    "\n",
    "det_model.prepare(ctx_id=0, input_size=(480, 640), det_thres=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:06<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 512)\n",
      "(1200, 512)\n",
      "(1200, 512)\n",
      "1200\n",
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import by_experiment\n",
    "import json\n",
    "\n",
    "def process_images(path, subjects=[0]):\n",
    "    undetected = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        embs_subject_path = f\"data/RGB/embs_{subject}.npy\"\n",
    "        if not os.path.exists(embs_subject_path):\n",
    "            subject_embeddings = []\n",
    "            print(f\"Subject: {subject}\")\n",
    "\n",
    "            for img_path in tqdm(sorted(glob(rf\"{path}\\{subject}\\*_colour.npy\"), key=by_experiment)):\n",
    "                for i, img in enumerate(np.load(img_path).astype(np.float32)):\n",
    "                    img = img[..., ::-1]\n",
    "                    bboxes, kpss = det_model.detect(img, max_num=0, metric=\"default\")\n",
    "                    if len(bboxes) != 1:\n",
    "                        undetected.append((img_path.split('\\\\')[-1], i))\n",
    "                        subject_embeddings.append(np.zeros((512)))\n",
    "                        continue\n",
    "                    face = Face(bbox=bboxes[0, :4], kps=kpss[0], det_score=bboxes[0, 4])\n",
    "                    rec_model.get(img, face)\n",
    "                    subject_embeddings.append(face.normed_embedding)\n",
    "\n",
    "            subject_embeddings = np.stack(subject_embeddings, axis=0)\n",
    "            print(subject_embeddings.shape)\n",
    "            np.save(embs_subject_path, subject_embeddings)\n",
    "    \n",
    "    if len(undetected) > 0:\n",
    "        with open('data/RGB/undetected.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(undetected, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def load_embeddings(path, subjects=[0]):\n",
    "    labels, unseen_labels = [], []\n",
    "    embeddings, unseen_embeddings = [], []\n",
    "    for subject in subjects:\n",
    "        embs_path = f\"{path}/embs_{subject}.npy\"\n",
    "        if os.path.exists(embs_path):\n",
    "            subject_embeddings = np.load(embs_path)\n",
    "            h = len(subject_embeddings)//2\n",
    "            embeddings.append(subject_embeddings[:h])\n",
    "            unseen_embeddings.append(subject_embeddings[h:])\n",
    "            labels += [subject]*len(subject_embeddings[:h])\n",
    "            unseen_labels += [subject]*len(subject_embeddings[h:])\n",
    "\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    unseen_embeddings = np.concatenate(unseen_embeddings, axis=0)\n",
    "\n",
    "    print(embeddings.shape)\n",
    "    print(unseen_embeddings.shape)\n",
    "    print(len(labels))\n",
    "    print(len(unseen_labels))\n",
    "    return labels, embeddings, unseen_labels, unseen_embeddings\n",
    "\n",
    "DATA_DIR = os.path.relpath(f\"../../Soli/soli_realsense/data\")\n",
    "subjects = list(range(16))\n",
    "process_images(DATA_DIR, subjects)\n",
    "labels, embeddings, unseen_labels, unseen_embeddings = load_embeddings(\"data/RGB\", subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def search_flatten(embeddings, labels, unseen_embeddings, threshold=0.5):\n",
    "    pred_names = []\n",
    "    for emb in unseen_embeddings:\n",
    "        scores = np.dot(emb, embeddings.T)\n",
    "        scores = np.clip(scores, 0., 1.)\n",
    "\n",
    "        idx = np.argmax(scores)\n",
    "        if scores[idx] > threshold:\n",
    "            pred_names.append(labels[idx])\n",
    "        else:\n",
    "            pred_names.append(None)\n",
    "    \n",
    "    return pred_names\n",
    "\n",
    "def get_averages(labels, scores):\n",
    "    d = defaultdict(list)\n",
    "    for l, s in zip(labels, scores):\n",
    "        d[l].append(s)\n",
    "    \n",
    "    return {n:np.mean(s) for n, s in d.items()}\n",
    "\n",
    "def search_average(embeddings, labels, unseen_embeddings, threshold=0.5):\n",
    "    pred_names = []\n",
    "    for emb in unseen_embeddings:\n",
    "        scores = np.dot(emb, embeddings.T)\n",
    "        scores = np.clip(scores, 0., 1.)\n",
    "\n",
    "        averages = get_averages(labels, scores)\n",
    "        pred = sorted(averages, key=lambda x: averages[x], reverse=True)[0]\n",
    "\n",
    "        if averages[pred] > threshold:\n",
    "            pred_names.append(pred)\n",
    "        else:\n",
    "            pred_names.append(None)\n",
    "    \n",
    "    return pred_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_labels, pred_labels):\n",
    "    coverage = np.mean([n is not None for n in pred_labels]) * 100.\n",
    "\n",
    "    is_corrects = [t == p for t, p in zip(true_labels, pred_labels) if p]\n",
    "    if not is_corrects:\n",
    "        is_corrects.append(False)\n",
    "\n",
    "    accuracy = np.mean(is_corrects) * 100.\n",
    "    return accuracy, coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flatten</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>average</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    method  accuracy   coverage\n",
       "0  flatten     100.0  98.333333\n",
       "1  average     100.0  95.583333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred_names = search_flatten(embeddings, labels, unseen_embeddings, threshold=0.45)\n",
    "acc_flatten, cov_flatten = evaluate(unseen_labels, pred_names)\n",
    "\n",
    "pred_names = search_average(embeddings, labels, unseen_embeddings, threshold=0.45)\n",
    "acc_average, cov_average = evaluate(unseen_labels, pred_names)\n",
    "\n",
    "# TODO: ALSO ACCOUNT FOR FAILURES -> UNDETECTED FACES ETC.\n",
    "results = pd.DataFrame([\n",
    "    {'method': 'flatten', 'accuracy': acc_flatten, 'coverage': cov_flatten},\n",
    "    {'method': 'average', 'accuracy': acc_average, 'coverage': cov_average},\n",
    "])\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
