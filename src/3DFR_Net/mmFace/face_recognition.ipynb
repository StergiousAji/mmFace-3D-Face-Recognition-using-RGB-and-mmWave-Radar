{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'enable_skip_layer_norm_strict_mode': '0'}, 'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'device_id': '0', 'gpu_external_alloc': '0', 'enable_cuda_graph': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'cudnn_conv_use_max_workspace': '1', 'cudnn_conv1d_pad_to_nc1d': '0', 'tunable_op_enable': '0', 'tunable_op_tuning_enable': '0', 'enable_skip_layer_norm_strict_mode': '0'}, 'CPUExecutionProvider': {}}\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "from insightface.app.common import Face\n",
    "from insightface.model_zoo import model_zoo\n",
    "from neural_nets import MMFace, MMFaceClassifier, insightface_model, InsightFaceClassifier, IntermediateFusionClassifier\n",
    "from utils import load_model\n",
    "import numpy as np\n",
    "# REQUIRED FOR CUDA TO BE USED\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_subjects = 21\n",
    "\n",
    "det_model = model_zoo.get_model(\"../models/buffalo_l/det_10g.onnx\")\n",
    "det_model.prepare(ctx_id=0, input_size=(480, 640), det_thres=0.5)\n",
    "rec_model = model_zoo.get_model(\"../models/buffalo_l/w600k_r50.onnx\")\n",
    "\n",
    "mmface_model = MMFace(2).to(device)\n",
    "mmface_model.load_state_dict(torch.load(f\"models/mmFace-liveness-99.6.pt\")[\"model_state_dict\"])\n",
    "mmface_model.eval()\n",
    "# TODO: MAKE READY FOR FEATURE EXTRACTION LAST LAYER\n",
    "\n",
    "insightface_classifier = InsightFaceClassifier(num_subjects).to(device)\n",
    "insightface_classifier.load_state_dict(torch.load(\"models/insightface_classifier.pt\")[\"model_state_dict\"])\n",
    "insightface_classifier.eval()\n",
    "\n",
    "# TODO: TRAIN (ONCE PAPER DATASET COLLECTED)\n",
    "# insightface_classifier_liveness = InsightFaceClassifier(2).to(device)\n",
    "# insightface_classifier_liveness.eval()\n",
    "#\n",
    "# mmface_classifier_liveness = MMFaceClassifier_Liveness().to(device)\n",
    "# mmface_classifier_liveness.load_state_dict(torch.load(\"models/mmFace-21_classifier.pt\")[\"model_state_dict\"])\n",
    "# mmface_classifier_liveness.eval()\n",
    "\n",
    "# TODO: NEED DATASET FOR THIS\n",
    "intermediate_fusion_clf = IntermediateFusionClassifier(512*2, num_subjects).to(device)\n",
    "\n",
    "# TODO: LOOP THROUGH DATASET IN ORDER AND RECOGNISE AND CLASSIFY FOR EVALUATION (LOAD DATA FOR EACH SUBJECT)\n",
    "def recognise(rgb_input, radar_input):\n",
    "    with torch.no_grad():\n",
    "        rgb_emb = insightface_model(rgb_input[..., ::-1], det_model, Face, rec_model)\n",
    "        # TODO: EXTRACT EMBEDDING FROM MODEL.FC2\n",
    "        radar_emb = mmface_model(radar_input)\n",
    "    \n",
    "    return rgb_emb, radar_emb\n",
    "\n",
    "def classify_no_radar(rgb_emb):\n",
    "    with torch.no_grad():\n",
    "        subject = insightface_classifier(rgb_emb)\n",
    "        liveness = insightface_classifier_liveness(rgb_emb)\n",
    "\n",
    "    return subject, liveness\n",
    "\n",
    "def classify(rgb_emb, radar_emb):\n",
    "    with torch.no_grad():\n",
    "        subject = insightface_classifier(rgb_emb)\n",
    "        liveness = mmface_classifier_liveness(radar_emb)\n",
    "    \n",
    "    return subject, liveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = \"../../Soli/soli_realsense/data\"\n",
    "\n",
    "def load_rgb(subject, experiment):\n",
    "    return np.load(f\"{DATA_PATH}/{subject}/{subject}-{experiment}_colour.npy\").astype(np.float32)\n",
    "\n",
    "def recognise_rgb(rgb_input):\n",
    "    return insightface_model(rgb_input[..., ::-1], det_model, Face, rec_model)\n",
    "\n",
    "fake_0 = recognise_rgb(load_rgb(90, 0)[0])\n",
    "fake_0_1 = recognise_rgb(load_rgb(90, 5)[0])\n",
    "real_0 = recognise_rgb(load_rgb(0, 0)[0])\n",
    "real_0_1 = recognise_rgb(load_rgb(0, 1)[0])\n",
    "real_1 = recognise_rgb(load_rgb(1, 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3785049319267273 0.0\n"
     ]
    }
   ],
   "source": [
    "score_good = np.clip(np.dot(fake_0_1, fake_0.T), 0., 1.)\n",
    "score_bad = np.clip(np.dot(fake_0, real_1.T), 0., 1.)\n",
    "\n",
    "print(score_good, score_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mmFace Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mmFace Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_builder import normalise, load_dataset_DL, load_dataset\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "subjects = range(21)\n",
    "num_subjects = len(subjects)\n",
    "experiments = list(range(15))\n",
    "num_frames = 250\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "train, validation, test = load_dataset(os.path.relpath(\"../../Soli/soli_realsense/data\"), subjects, experiments=experiments, num_frames=num_frames, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from neural_nets import MMFaceFE, MMFaceClassifier\n",
    "from utils import load_model, load_history\n",
    "\n",
    "num_epochs = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = MMFaceFE().to(device)\n",
    "\n",
    "# Loss + Optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.001, momentum=0.9)\n",
    "\n",
    "model_name = f\"mmFaceFE-{num_subjects}.pt\"\n",
    "cur_epoch, loss_history, train_acc, val_acc = load_model(model_name, model, optimiser)\n",
    "\n",
    "if len(loss_history) > 0:\n",
    "    print(f\"{model_name}\\n\\tEpoch: {cur_epoch}\\n\\tLoss: {loss_history[-1]:.4f}\\n\\tTrain Accuracy: {train_acc[-1]:.4f}\\n\\tValidation Accuracy: {val_acc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(cur_epoch, num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch}/{num_epochs-1}]:\")\n",
    "    if os.path.exists(f\"models/{model_name}\"):\n",
    "        loss_history, train_acc, val_acc = load_history(f\"models/{model_name}\")\n",
    "\n",
    "    model.train()\n",
    "    # Running Loss and Accuracy\n",
    "    running_loss, running_acc, total = 0., 0., 0.\n",
    "\n",
    "    for data, labels in tqdm(train):\n",
    "        # Forward Pass\n",
    "        outputs = model(data)\n",
    "        print(outputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(predicted)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward Pass and Optimise\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        # running_loss += loss.item()\n",
    "        # total += labels.size(0)\n",
    "        # running_acc += (predicted == labels).sum().item()\n",
    "\n",
    "        del data, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    avg_train_loss = running_loss/len(train)\n",
    "    # avg_train_acc = 100*running_acc/total\n",
    "    print(f\"\\tAverage Train Loss: {avg_train_loss:.4f}\")\n",
    "    # print(f\"\\tTrain Accuracy: {avg_train_acc:.4f}%\")\n",
    "\n",
    "    torch.save({\"epoch\": epoch+1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimiser_state_dict\": optimiser.state_dict(),\n",
    "                \"loss_history\": loss_history + [avg_train_loss],\n",
    "                \"train_acc\": train_acc,\n",
    "                \"val_acc\": val_acc},\n",
    "                f\"models/{model_name}\")\n",
    "    \n",
    "    # # Validation\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     correct = 0\n",
    "    #     total = 0\n",
    "    #     for data, labels in validation:\n",
    "    #         outputs = model(data)\n",
    "    #         _, predicted = torch.max(outputs.data, 1)\n",
    "    #         total += labels.size(0)\n",
    "    #         correct += (predicted == labels).sum().item()\n",
    "    #         del data, labels, outputs\n",
    "        \n",
    "    #     avg_val_acc = 100*correct/total\n",
    "    #     print(f\"\\tValidation Accuracy: {avg_val_acc:.4f}%\")\n",
    "\n",
    "    # model_checkpoint = torch.load(f\"models/{model_name}\")\n",
    "    # model_checkpoint[\"val_acc\"].append(avg_val_acc)\n",
    "    # torch.save(model_checkpoint, f\"models/{model_name}\")\n",
    "\n",
    "    # # Stop if overfitting\n",
    "    # if avg_train_acc - avg_val_acc > 5:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SAVE EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mmFace Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mmFace Embeddings Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: LOAD EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MMFaceClassifier(num_subjects).to(device)\n",
    "criterion_clf = nn.CrossEntropyLoss()\n",
    "optimiser_clf = torch.optim.SGD(classifier.parameters(), lr=learning_rate, weight_decay=0.001, momentum=0.9)\n",
    "\n",
    "classifier_name = f\"mmFaceClassifier-{num_subjects}.pt\"\n",
    "cur_epoch, loss_history, train_acc, val_acc = load_model(classifier_name, classifier, optimiser_clf)\n",
    "\n",
    "if len(loss_history) > 0:\n",
    "    print(f\"{model_name}\\n\\tEpoch: {cur_epoch}\\n\\tLoss: {loss_history[-1]:.4f}\\n\\tTrain Accuracy: {train_acc[-1]:.4f}\\n\\tValidation Accuracy: {val_acc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(cur_epoch, num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch}/{num_epochs-1}]:\")\n",
    "    if os.path.exists(f\"models/{classifier_name}\"):\n",
    "        loss_history, train_acc, val_acc = load_history(f\"models/{classifier_name}\")\n",
    "\n",
    "    classifier.train()\n",
    "    # Running Loss and Accuracy\n",
    "    running_loss, running_acc, total = 0., 0., 0.\n",
    "\n",
    "    for data, labels in tqdm(train):\n",
    "        # Forward Pass\n",
    "        outputs = classifier(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        loss = criterion_clf(outputs, labels)\n",
    "\n",
    "        # Backward Pass and Optimise\n",
    "        optimiser_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser_clf.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        running_acc += (predicted == labels).sum().item()\n",
    "\n",
    "        del data, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    avg_train_loss = running_loss/len(train)\n",
    "    avg_train_acc = 100*running_acc/total\n",
    "    print(f\"\\tAverage Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"\\tTrain Accuracy: {avg_train_acc:.4f}%\")\n",
    "\n",
    "    torch.save({\"epoch\": epoch+1,\n",
    "                \"model_state_dict\": classifier.state_dict(),\n",
    "                \"optimiser_state_dict\": optimiser_clf.state_dict(),\n",
    "                \"loss_history\": loss_history + [avg_train_loss],\n",
    "                \"train_acc\": train_acc + [avg_train_acc],\n",
    "                \"val_acc\": val_acc},\n",
    "                f\"models/{classifier_name}\")\n",
    "    \n",
    "    # Validation\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, labels in validation:\n",
    "            outputs = classifier(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del data, labels, outputs\n",
    "        \n",
    "        avg_val_acc = 100*correct/total\n",
    "        print(f\"\\tValidation Accuracy: {avg_val_acc:.4f}%\")\n",
    "\n",
    "    classifier_checkpoint = torch.load(f\"models/{classifier_name}\")\n",
    "    classifier_checkpoint[\"val_acc\"].append(avg_val_acc)\n",
    "    torch.save(classifier_checkpoint, f\"models/{classifier_name}\")\n",
    "\n",
    "    # Stop if overfitting\n",
    "    if avg_train_acc - avg_val_acc > 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dfr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
